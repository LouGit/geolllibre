#!/usr/bin/rebol -qs
rebol []
; Script de transfert:
;2018_09_10__14_27_50
;# Transfert des données depuis la base bdexplo, historique, vers la base postgeol, après un gros ménage.
;# Script scindé en paragraphes à faire tourner, au furàmz, par des F8 bien sentis. Ou plutôt des F6. => bof.

; Définition des bases de départ et d'arrivée:
bd_depart: make object!			[	base: "bdexplo"		host: "autan"	]
bd_destination: make object!	[	base: "postgeol"	host: "autan"	]
connexion_bd_depart:  does      [
	dbname:   bd_depart/base
	hostname: bd_depart/host
	connection_db               ]
connexion_bd_destination: does  [
	dbname: bd_destination/base
	dbhost: bd_destination/host
	connection_db               ]
; x la liste des tables de autan_bdexplo:{{{
connexion_bd_depart
tables_start: run_query "SELECT schemaname || '.' || tablename FROM pg_tables WHERE schemaname NOT IN ('backups', 'information_schema', 'pg_catalog', 'tmp_a_traiter', 'tmp_imports', 'tmp_ntoto', 'topology') ORDER BY 1;"
;}}}
; x la liste des tables de autan_postgeol{{{
connexion_bd_destination
tables_destination: run_query "SELECT schemaname || '.' || tablename FROM pg_tables WHERE schemaname NOT IN ('backups', 'information_schema', 'pg_catalog', 'tmp_a_traiter', 'tmp_imports', 'tmp_ntoto', 'topology') ORDER BY 1;"
;}}}
; x l'intersection des deux listes = la liste des tables à transférer:{{{
tables_a_transferer: intersect tables_destination tables_start
;
;}}}
print rejoin [ length? tables_start " tables de la base de départ, " length? tables_destination " tables dans la base de destination, "length? tables_a_transferer " tables communes sont à tranférer."]
print "Les tables présentes seulement dans la base d'arrivée sont:"
foreach t (exclude tables_destination tables_start) [ print t ]

;NB: shift_reports => dh_shift_reports
; Ah oui, mais bon, en fait, il faut mettre ces tables dans un certain ordre, pour que ça passe, avec les contraintes d'intégrité référentielles: {{{

;>> foreach t tables_a_transferer [write/append/lines %/tmp/qty first t]
;:r /tmp/qty dans vim, et trafic:

tables_a_transferer: [
public.operations
pierre.operation_active
public.dh_collars
public.dh_core_boxes
public.dh_density
public.dh_devia
public.dh_followup
public.dh_litho
public.dh_mineralised_intervals
public.dh_photos
public.dh_quicklog
public.dh_radiometry
public.dh_resistivity
public.dh_samples_submission
public.dh_sampling_bottle_roll
public.dh_sampling_grades
public.dh_struct_measures
public.dh_tech
public.dh_thinsections
public.field_observations
public.field_observations_struct_measures
public.field_photos
public.formations_group_lithos
public.geoch_ana
public.geoch_sampling
public.geoch_sampling_grades
public.gpy_mag_ground
public.grade_ctrl
public.index_geo_documentation
public.lab_ana_batches_expedition
public.lab_ana_batches_reception
public.lab_ana_columns_definition
public.lab_analysis_icp
public.lab_ana_qaqc_results
public.lab_ana_results
public.lex_codes
public.lex_datasource
public.lex_standard
public.licences
public.ana_det_limit
public.ancient_workings
public.baselines
public.conversions_oxydes_elements
public.mag_declination
public.occurrences
public.qc_sampling
public.qc_standards
public.sections_array
public.sections_definition
public.spatial_ref_sys
public.surface_samples_grades
public.survey_lines
public.topo_points
public.units
]

comment [ ;{{{
;>> write %/tmp/qty ""
;>> foreach t tables_autan_bdexplo [write/append/lines %/tmp/qty first t]
pierre.ana_det_limit
pierre.coords
pierre.dh_collars_lengths
pierre.dh_nb_samples
pierre.dh_photos
pierre.dh_samples_submission
pierre.gps_wpt
pierre.grid
pierre.lab_ana_batches_reception_18_corr
pierre.lab_analysis_icp
pierre.layer_styles
pierre.program
pierre.sections_array
pierre.sections_definition
pierre.sondages_ims_4326
pierre.tmp_chanac
pierre.tmp_mine_plant_daily_production
pierre.tmp_xy
pierre.tmp_xyz_marec
pierre.toto
pierre.toudoux_dh_sampling_grades_datasource_979
pierre.tt
pierre.tt_bdexplo_lex_datasource_autan
pierre.tt_bdexplo_lex_labo_analysis_autan
public.ancient_workings
public.baselines
public.conversions_oxydes_elements
public.dh_collars
public.dh_core_boxes
public.dh_core_boxes_runs_xyz
public.dh_density
public.dh_density_runs_xyz
public.dh_devia
public.dh_devia_runs_xyz
public.dh_followup
public.dh_litho
public.dh_litho_runs_xyz
public.dh_mineralised_intervals
public.dh_mineralised_intervals_runs_xyz
public.dh_quicklog
public.dh_quicklog_runs_xyz
public.dh_radiometry
public.dh_radiometry_runs_xyz
public.dh_resistivity
public.dh_resistivity_runs_xyz
public.dh_sampling_bottle_roll
public.dh_sampling_bottle_roll_runs_xyz
public.dh_sampling_grades
public.dh_sampling_grades_runs_xyz
public.dh_struct_measures
public.dh_struct_measures_runs_xyz
public.dh_tech
public.dh_tech_runs_xyz
public.dh_thinsections
public.dh_thinsections_runs_xyz
public.doc_bdexplo_tables_descriptions
public.doc_postgeol_table_categories
public.field_observations
public.field_observations_struct_measures
public.field_photos
public.field_sampling
public.field_sampling_ana
public.formations_group_lithos
public.geoch_ana
public.geoch_sampling
public.geoch_sampling_grades
public.geometry_columns_old
public.gpy_mag_ground
public.grade_ctrl
public.index_geo_documentation
public.lab_ana_batches_expedition
public.lab_ana_batches_reception
public.lab_ana_columns_definition
public.lab_ana_qaqc_results
public.lab_ana_results
public.lex_codes
public.lex_datasource
public.lex_standard
public.licences
public.mag_declination
public.mine_plant_daily_production
public.occurrences
public.occurrences_recup_depuis_dump
public.operation_active
public.operations
public.qc_sampling
public.qc_standards
public.shift_reports
public.spatial_ref_sys
public.spatial_ref_sys_old
public.surface_samples_grades
public.survey_lines
public.topo_points
public.units

;public.spatial_ref_sys
] ;}}}
;}}}
; Création d'un schéma temporaire:
; (après un peu de ménage, au cas où la procédure aurait précédemment échoué)
sql_txt: "DROP SCHEMA tmp_exports CASCADE;"
append sql_txt newline
append sql_txt "CREATE SCHEMA IF NOT EXISTS tmp_exports;"
;e recopie de toutes les tables à transférer dans le schéma temporaire pour exports:{{{
append sql_txt newline
foreach t tables_a_transferer [
	parse to-string t [ copy s to "." thru "." copy t to end] 		; print s print t
	append sql_txt rejoin ["CREATE TABLE tmp_exports." s "_" t " AS SELECT * FROM " s "." t ";" newline]
	]
write %/tmp/copy_tables_tmp_exports sql_txt
call_wait_output_error rejoin ["psql -X -h " bd_depart/host " -d " bd_depart/base { -1 -f /tmp/copy_tables_tmp_exports} ]
;}}}
;o on enlève certains champs à toutes les tables:{{{

foreach t tables_a_transferer [
	parse to-string t [ copy s to "." thru "." copy t to end]
	append sql_txt rejoin ["ALTER TABLE tmp_exports." s "_" t " DROP COLUMN IF EXISTS numauto;" newline]
	]

}}}
_______________ENCOURS_______________GEOLLLIBRE
; e dompage de ces tables depuis autan_bdexplo dans des fontchiers:{{{

dbname: bd_depart/base
dbhost: bd_depart/host
connection_db

foreach t tables_a_transferer [
	                           print t ]
t: first tables_a_transferer ; ########DEBUG
append cmd rejoin ["CREATE TABLE public.tt_" t " AS SELECT * FROM " t ";" newline]
append cmd rejoin ["ALTER TABLE public.tt_"  t " DROP COLUMN numauto;"    newline]


cmd: copy ""
	append cmd rejoin ["pg_dump -h " bd_depart/host " -d " bd_depart/base " --disable-triggers --no-owner -a -t tt_" t { > /tmp/} t ".sql" newline]
call_wait_output_error cmd

"createdb tmp"




--inserts
;{ | grep -v "^--" | grep -v "^$"

sed -i "s/(opid, operation, full_name, operator, year, confidentiality, lat_min, lon_min, lat_max, lon_max, comments, creation_ts, username, numauto)/(opid, name_short, name_full, operator, year, confidentiality, lat_min, lon_min, lat_max, lon_max, comments, creation_ts, username, numauto)/g" /tmp/public.operations.sql

; mince, les numauto, creation_ts, username ne sont pas remplis automatiquement par la base, quand on fait ainsi. Hm.

append cmd
call_wait_output_error rejoin ["psql -X -h " bd_destination/host " -d " bd_destination/base { -f /tmp/} t ".sql" newline]
]



pg_dump bdexplo -t tmp_imports.tmp_tmp_tous_resultats_acme_lab_ana_batches_reception --inserts --no-owner > script_`date +%Y_%m_%d_%Hh%M`.sql
pg_dump bdexplo -t tmp_imports.tmp_results_multi_elt --inserts --no-owner > script_`date +%Y_%m_%d_%Hh%M`.sql
postgres@duran:~$ pg_dump -Fc bdexplo > database_duran_9_0_bdexplo_`date +%Y_%m_%d_%Hh%M`.pg_dump
pg_dump -h duran -n public -n checks -n input -n stats_reports -O -s bdexplo -U postgres > schema_bdexplo_duran
pg_dump -h autan -n public -n checks -n input -n stats_reports -O -s bdexplo -U postgres > schema_bdexplo_autan

pg_dump -h duran -n public -O -s bdexplo -U postgres > schema_bdexplo_duran_public
pg_dump -h autan -n public -O -s bdexplo -U postgres > schema_bdexplo_autan_public
cat schema_bdexplo_autan_public | grep -v "^-" > schema_bdexplo_autan_public_sans_commentaires
cat schema_bdexplo_duran_public | grep -v "^-" > schema_bdexplo_duran_public_sans_commentaires
vimdiff schema_bdexplo_duran_public_sans_commentaires schema_bdexplo_autan_public_sans_commentaires

pg_restore -C -d toto -t public.def_sampling_grades_fields database_autan_bdexplo_2013_08_08_08h52.pg_dump


}}}
; o mettre les données de ces tables dans autan_postgeol depuis le dompage:

; o voir les erreurs, et sed le fichier de dump
; o réitérer


-- à la fin, nettoyer: DROP TABLE tmp_exports.*;  DROP SCHEMA 'tmp_exports';







{{{
__________***_JEANSUILA_***__________
pg_dump -d bdexplo -a -t public.doc_postgeol_table_categories | sed -e 's/doc_bdexplo_/doc_postgeol_/g'    |  psql postgeol --single-transaction
pg_dump -d bdexplo -a -t public.doc_bdexplo_tables_descriptions  | sed -e 's/doc_bdexplo_/doc_postgeol_/g' |  psql postgeol --single-transaction
__________***_JEANSUILA_***__________

psql postgeol -c "ALTER TABLE public.operations ADD COLUMN numauto integer;"
pg_dump -d bdexplo -a -t public.operations | grep -v "operations_numauto_seq"    |  psql postgeol --single-transaction
psql postgeol -c "ALTER TABLE public.operations DROP COLUMN numauto;"

SELECT * FROM public.operations;






> /tmp/tt && less /tmp/tt
psql postgeol -f /tmp/tt



}}}

